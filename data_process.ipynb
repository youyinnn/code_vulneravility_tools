{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Node Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 19246),\n",
       " ('expr', 4746),\n",
       " ('decl', 2954),\n",
       " ('literal', 2802),\n",
       " ('type', 2800),\n",
       " ('if', 1644),\n",
       " ('try', 1552),\n",
       " ('function', 1272),\n",
       " ('block_content', 1204),\n",
       " ('call', 1136),\n",
       " ('condition', 1104),\n",
       " ('catch', 1090),\n",
       " ('throws', 1002),\n",
       " ('block', 773),\n",
       " ('init', 738),\n",
       " ('specifier', 722),\n",
       " ('if_stmt', 461),\n",
       " ('operator', 392),\n",
       " ('parameter_list', 388),\n",
       " ('parameter', 388),\n",
       " ('finally', 348),\n",
       " ('argument', 238),\n",
       " ('decl_stmt', 212),\n",
       " ('index', 116),\n",
       " ('for', 110),\n",
       " ('else', 101),\n",
       " ('return', 75),\n",
       " ('control', 60),\n",
       " ('expr_stmt', 20),\n",
       " ('incr', 20)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re\n",
    "\n",
    "def read_out_dep_freq(data_set_name):\n",
    "    with open(os.path.join('srcxml', f'{data_set_name}_out', 'de2freq.txt')) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        node_freq = {}\n",
    "        \n",
    "        for line in lines:\n",
    "            sp = re.split('\\s+', line.strip())\n",
    "            freq = sp[0]\n",
    "            nodes = [s for s in re.split('[-|↓|↑]', sp[1]) if s != '']\n",
    "\n",
    "            for node in nodes:\n",
    "                if node_freq.get(node) == None:\n",
    "                    node_freq[node] = 0\n",
    "                node_freq[node] += int(freq)\n",
    "                \n",
    "        node_freq_list = []\n",
    "        for k, v in node_freq.items():\n",
    "            node_freq_list.append((k, v))\n",
    "            \n",
    "        node_freq_list = sorted(node_freq_list, key=lambda a: a[1], reverse=True)\n",
    "        \n",
    "        return node_freq_list\n",
    "                \n",
    "        \n",
    "read_out_dep_freq('juliet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Filtered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_out_data(data_set_name):\n",
    "    def read_out_de_2_id(data_set_name):\n",
    "        with open(os.path.join('srcxml', f'{data_set_name}_out', 'de2id.txt')) as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "            id2de = {}\n",
    "            \n",
    "            for line in lines:\n",
    "                sp = re.split('\\s+', line.strip())\n",
    "                id2de[int(sp[-1])] = sp[0]\n",
    "                \n",
    "            return id2de\n",
    "        \n",
    "    id2de = read_out_de_2_id('juliet')\n",
    "\n",
    "    def read_out_voc_2_id(data_set_name):\n",
    "        with open(os.path.join('srcxml', f'{data_set_name}_out', 'voc2id.txt')) as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "            id2voc = {}\n",
    "            \n",
    "            for line in lines:\n",
    "                sp = re.split('\\s+', line.strip())\n",
    "                id2voc[int(sp[-1])] = sp[0]\n",
    "                \n",
    "            return id2voc\n",
    "\n",
    "    id2voc = read_out_voc_2_id('juliet')\n",
    "    \n",
    "    data_list = []\n",
    "    with open(os.path.join('srcxml', f'{data_set_name}_out', 'data.txt')) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        \n",
    "        for line in lines:\n",
    "            sp = line.strip().split(' ')\n",
    "            \n",
    "            num_words = int(sp[0])\n",
    "            num_dep_rels = int(sp[1])\n",
    "            \n",
    "            token_id_list = sp[2:2+num_words]\n",
    "            dep_path_list = sp[2+num_words:]\n",
    "            \n",
    "            decode_dep_path = []\n",
    "            \n",
    "            for dep_path in dep_path_list:\n",
    "                srcT, desT, dep = dep_path.split('|')\n",
    "                decode_dep_path.append(\n",
    "                    {\n",
    "                        \"srcT\": id2voc[int(token_id_list[int(srcT)])],\n",
    "                        \"desT\": id2voc[int(token_id_list[int(desT)])],\n",
    "                        \"path\": id2de[int(dep)],\n",
    "                    }\n",
    "                )\n",
    "        \n",
    "            data_list.append(\n",
    "                decode_dep_path\n",
    "            )\n",
    "            \n",
    "    return data_list\n",
    "        \n",
    "from tqdm import tqdm\n",
    "\n",
    "def filter_decoded_data_list(data_set_name, removed_node_list):\n",
    "    decoded_data_list = read_out_data('juliet')\n",
    "    filtered_decoded_data_list = []\n",
    "    for i in tqdm(range(len(decoded_data_list))):\n",
    "        decoded_data = decoded_data_list[i]\n",
    "        filtered_decoded_data = []\n",
    "        for j in range(len(decoded_data)):\n",
    "            dep_path = decoded_data[j]\n",
    "            current_nodes = [s for s in re.split('[-|↓|↑]', dep_path['path']) if s != '']\n",
    "            removed = False\n",
    "            for node in current_nodes:\n",
    "                if node in removed_node_list:\n",
    "                    removed = True\n",
    "                    break\n",
    "                \n",
    "            if not removed:\n",
    "                filtered_decoded_data.append(dep_path)\n",
    "        filtered_decoded_data_list.append(filtered_decoded_data)\n",
    "        \n",
    "    return filtered_decoded_data_list\n",
    "\n",
    "def get_rs_obj_from_filtered_data_list(data_set_name, removed_node_list):\n",
    "    \n",
    "    decoded_data_list = filter_decoded_data_list(data_set_name, removed_node_list)\n",
    "    \n",
    "    rs_obj = dict(\n",
    "        token_id_map = {},\n",
    "        token_frequecy_map = {},\n",
    "        dep_id_map = {},\n",
    "        dep_frequecy_map = {},\n",
    "        sentence_triples = [],\n",
    "    )\n",
    "    \n",
    "    for decoded_data in decoded_data_list:\n",
    "        triples = []\n",
    "        for triple in decoded_data:\n",
    "            srcT = triple['srcT'] \n",
    "            desT = triple['desT'] \n",
    "            dep_path = triple['path']\n",
    "            \n",
    "            if rs_obj['token_id_map'].get(srcT) == None:\n",
    "                rs_obj['token_id_map'][srcT] = len(rs_obj['token_id_map'].keys())\n",
    "                \n",
    "            if rs_obj['token_frequecy_map'].get(srcT) == None:\n",
    "                rs_obj['token_frequecy_map'][srcT] = 0\n",
    "                \n",
    "            rs_obj['token_frequecy_map'][srcT] += 1\n",
    "                \n",
    "            if rs_obj['token_id_map'].get(desT) == None:\n",
    "                rs_obj['token_id_map'][desT] = len(rs_obj['token_id_map'].keys())\n",
    "                \n",
    "            if rs_obj['token_frequecy_map'].get(desT) == None:\n",
    "                rs_obj['token_frequecy_map'][desT] = 0\n",
    "                \n",
    "            rs_obj['token_frequecy_map'][desT] += 1\n",
    "            \n",
    "            if rs_obj['dep_id_map'].get(dep_path) == None:\n",
    "                rs_obj['dep_id_map'][dep_path] = len(rs_obj['dep_id_map'].keys())\n",
    "                \n",
    "            if rs_obj['dep_frequecy_map'].get(dep_path) == None:\n",
    "                rs_obj['dep_frequecy_map'][dep_path] = 0\n",
    "            \n",
    "            rs_obj['dep_frequecy_map'][dep_path] += 1\n",
    "            \n",
    "            triples.append((\n",
    "                rs_obj['token_id_map'][srcT],\n",
    "                rs_obj['token_id_map'][desT],\n",
    "                rs_obj['dep_id_map'][dep_path]\n",
    "            ))\n",
    "        \n",
    "        rs_obj['sentence_triples'].append(triples)\n",
    "    \n",
    "    return rs_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:00<00:00, 4900.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# remove all deps which contain 'specifier' node in the path\n",
    "rs_obj = get_rs_obj_from_filtered_data_list('juliet', ['specifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputData(data_set_name, rs_obj):\n",
    "    out_dir = os.path.join('srcxml', f'{data_set_name}_out')\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    \n",
    "    with open(os.path.join(out_dir, f'voc2id.txt'), 'w') as f:\n",
    "        for _tk, _id in rs_obj['token_id_map'].items():\n",
    "            f.write(f'{_tk}\\t{_id}\\r\\n')\n",
    "            \n",
    "    with open(os.path.join(out_dir, f'id2freq.txt'), 'w') as f:\n",
    "        for _tk, _feq in rs_obj['token_frequecy_map'].items():\n",
    "            _id = rs_obj['token_id_map'][_tk]\n",
    "            f.write(f'{_id}\\t{_feq}\\r\\n')\n",
    "\n",
    "    with open(os.path.join(out_dir, f'de2id.txt'), 'w') as f:\n",
    "        for _dep, _id in rs_obj['dep_id_map'].items():\n",
    "            f.write(f'{_dep}\\t{_id}\\r\\n')\n",
    "            \n",
    "    with open(os.path.join(out_dir, f'de2freq.txt'), 'w') as f:\n",
    "        for _dep, _feq in rs_obj['dep_frequecy_map'].items():\n",
    "            f.write(f'{_feq}\\t\\t{_dep}\\r\\n')\n",
    "            \n",
    "    with open(os.path.join(out_dir, f'data.txt'), 'w') as f:\n",
    "        for sentence_triples in rs_obj['sentence_triples']:\n",
    "            tk_set = set([])\n",
    "            dep_path_list = []\n",
    "            for triple in sentence_triples:\n",
    "                srcT_id, desT_id, dep_path_id = triple\n",
    "                tk_set.add(srcT_id)\n",
    "                tk_set.add(desT_id)\n",
    "                \n",
    "                dep_path_list.append((srcT_id, desT_id, dep_path_id))\n",
    "                \n",
    "            tk_id_list = list(tk_set)\n",
    "            \n",
    "            # dep_path_list = [f\"{sdd[0]}|{sdd[1]}|{sdd[2]}\" for sdd in dep_path_list]\n",
    "            dep_path_list = [f\"{tk_id_list.index(sdd[0])}|{tk_id_list.index(sdd[1])}|{sdd[2]}\" for sdd in dep_path_list]\n",
    "            \n",
    "            f.write(f'{len(tk_id_list)} ')\n",
    "            f.write(f'{len(dep_path_list)} ')\n",
    "            f.write(' '.join([str(_id) for _id in tk_id_list]))\n",
    "            f.write(' ')\n",
    "            f.write(' '.join(dep_path_list))\n",
    "            f.write('\\r\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputData('juliet_new', rs_obj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_vul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1d94bd9d63b758d4d1a7745f354208240ecdb83ffa155a8e3719b77fc7247b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
